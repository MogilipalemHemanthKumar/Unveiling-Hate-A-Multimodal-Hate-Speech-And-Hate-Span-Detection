# Unveiling-Hate-A-Multimodal-Hate-Speech-And-Hate-Span-Detection

Hate speech detection in online environments presents a formidable challenge
due to its nuanced and multifaceted nature. In this study, we investigate hate
speech detection using multimodal approaches, integrating information from text
and images for memes, emojis, and hate speech span identification. Leveraging
advanced deep learning and natural language processing techniques, including
state-of-the-art transformer models, we develop models capable of accurately
identifying stances of hate speech in diverse online content. Additionally, we
employ explainable AI methodologies and prompt engineering techniques to pro-
vide insights into the decision-making process of our detection systems, enhancing
transparency and interpretability. The task is divided into three different sections
namely hate meme detection, Hate speech span detection, Hatemoji Detection.
Our proposed Encoder-Decoder model for Hateful Meme Detection achieved an
accuracy of approximately 72.4% and an AUC of around 72.9%, while Visual
Question Answering (LLAVA) attained an accuracy of 73.6% and an AUC of
75.8%. Our proposed models achieved better performance than the existing state
of the art Multimodal Models. In Hate Speech Span Detection, Our proposed
Explainable AI Model achieved a F1 Score of (0.6683) which is better than Spacy
modelâ€™s (0.640) performance. In the task of Hatemoji Detection, the GPT-3.5
model with prompt engineering achieved remarkable results, setting a bench-
mark with high precision (0.8369), recall (0.8570) , and F1 score (0.8463), which
is more than state of the art models like Deberta etc. As for our knowledge, this
is the first work, using prompt engineering for hatemoji detection
